{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prashant\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Replaced.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.didPurchase = (df.didPurchase)*1\n",
    "df.doRecommend = (df.doRecommend)*1\n",
    "\n",
    "df['doRecommend'] = df['doRecommend'].fillna(1)\n",
    "df['didPurchase'] = df['didPurchase'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['didPurchase','rating']]\n",
    "y=df['doRecommend']\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier(n_neighbors=10)\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),('knn',clf4)], voting='hard')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFore...wski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484531242664663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.score( X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting classifier gives an accuracy of 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944 (+/- 0.035) [Logistic Regression]\n",
      "Accuracy: 0.954 (+/- 0.029) [Random Forest]\n",
      "Accuracy: 0.948 (+/- 0.036) [naive Bayes]\n",
      "Accuracy: 0.947 (+/- 0.037) [KNN]\n",
      "Accuracy: 0.946 (+/- 0.037) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3,clf4, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'KNN','Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=20, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Staked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, valid, ytraining, yvalid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(training,ytraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(training,ytraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=clf2.predict(valid)\n",
    "preds2=clf4.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds1=clf2.predict(X_test)\n",
    "test_preds2=clf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predictions=np.column_stack((preds1,preds2))\n",
    "stacked_test_predictions=np.column_stack((test_preds1,test_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model=LinearRegression()\n",
    "meta_model.fit(stacked_predictions,yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions=meta_model.predict(stacked_test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[];\n",
    "y_list=y_test.tolist()\n",
    "for i in range(len(y_list)):\n",
    "    if (y_list[i]==np.round(final_predictions[i])):\n",
    "        count.append(\"Correct\")\n",
    "    else:\n",
    "        count.append(\"Incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12fc4022cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9570442702220553"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,np.round(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Stacked Ensemble with Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stack(clf, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions):\n",
    "    clf.fit(training,ytraining)\n",
    "    preds=clf.predict(valid)\n",
    "    test_preds=clf.predict(X_test)\n",
    "    stacked_predictions=np.append(stacked_predictions,preds)\n",
    "    stacked_test_predictions=np.append(stacked_test_predictions,test_preds)\n",
    "    return {'pred':stacked_predictions,'test':stacked_test_predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "    training, valid, ytraining, yvalid = train_test_split(X_train, y_train, test_size=0.3, random_state=None) \n",
    "    #kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=None) \n",
    "    #for train_index, test_index in kf.split(X):\n",
    "     #   training, valid = X.iloc[train_index], X.iloc[test_index] \n",
    "      #  ytraining, yvalid = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf2.fit(training,ytraining)\n",
    "    clf4.fit(training,ytraining)\n",
    "    preds1=clf2.predict(valid)\n",
    "    preds2=clf4.predict(valid)\n",
    "    test_preds1=clf2.predict(X_test)\n",
    "    test_preds2=clf4.predict(X_test)\n",
    "    stacked_predictions=np.column_stack((preds1,preds2))\n",
    "    stacked_test_predictions=np.column_stack((test_preds1,test_preds2))\n",
    "    #print(stacked_predictions.shape)\n",
    "    #print(stacked_test_predictions.shape)\n",
    "    meta_model=KNeighborsClassifier(n_neighbors=10)\n",
    "    meta_model.fit(stacked_predictions,yvalid)\n",
    "    final_predictions=meta_model.predict(stacked_test_predictions)\n",
    "    return accuracy_score(y_test,final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957\n",
      "0.954\n",
      "0.956\n",
      "0.958\n",
      "0.957\n",
      "0.958\n",
      "0.954\n",
      "0.957\n",
      "0.957\n",
      "0.932\n",
      "[0.9566217548471903, 0.9542744472090512, 0.9563400779306136, 0.9580301394300738, 0.9567156471527158, 0.9575606779024459, 0.953898877986949, 0.9569973240692925, 0.9566217548471903, 0.9318341861884418]\n",
      "Mean 0.954\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "for i in range(10):\n",
    "    accuracies.append(stacked())\n",
    "    print(\"%0.3f\" % accuracies[i])\n",
    "print(accuracies)\n",
    "mean_acc=sum(accuracies) / float(len(accuracies))\n",
    "print(\"Mean %0.3f\" % mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated KFold with X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "def stacked2():\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "    #training, valid, ytraining, yvalid = train_test_split(X_train, y_train, test_size=0.3, random_state=None) \n",
    "    kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=None) \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        training, valid, ytraining, yvalid = train_test_split(X_train, y_train, test_size=0.3, random_state=None) \n",
    "        stacked_predictions=[]\n",
    "        stacked_test_predictions=[]\n",
    "        result=fit_stack(clf2, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        result=fit_stack(clf4, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        result=fit_stack(clf3, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        meta_model=KNeighborsClassifier(n_neighbors=10)\n",
    "        meta_model.fit(stacked_predictions.reshape(-1,3),yvalid)\n",
    "        final_predictions=meta_model.predict(stacked_test_predictions.reshape(-1,3))\n",
    "        acc=accuracy_score(y_test,final_predictions)\n",
    "        accuracies.append(acc)\n",
    "    print(accuracies)\n",
    "    mean_acc=sum(accuracies) / float(len(accuracies))\n",
    "    print(\"Mean %0.3f\" % mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9321174565171467, 0.9322582916696007, 0.9308499401450602, 0.9314788732394366, 0.9322535211267605, 0.9307795225688332, 0.9312724456024224, 0.9318357862122386, 0.9361267605633803, 0.928943661971831]\n",
      "Mean 0.932\n"
     ]
    }
   ],
   "source": [
    "stacked2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated KFold with X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "def stacked1():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "    kf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=None) \n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        \n",
    "        training, valid = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        ytraining, yvalid = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        stacked_predictions=[]\n",
    "        stacked_test_predictions=[]\n",
    "        result=fit_stack(clf2, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        result=fit_stack(clf4, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        result=fit_stack(clf3, training, valid, ytraining,X_test,stacked_predictions,stacked_test_predictions)\n",
    "        stacked_predictions=result['pred']\n",
    "        stacked_test_predictions=result['test']\n",
    "        meta_model=KNeighborsClassifier(n_neighbors=10)\n",
    "        meta_model.fit(stacked_predictions.reshape(-1,3),yvalid)\n",
    "        final_predictions=meta_model.predict(stacked_test_predictions.reshape(-1,3))\n",
    "        acc=accuracy_score(y_test,final_predictions)\n",
    "        accuracies.append(acc)\n",
    "    print(accuracies)\n",
    "    mean_acc=sum(accuracies) / float(len(accuracies))\n",
    "    print(\"Mean %0.3f\" % mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.932021970799493, 0.932021970799493, 0.932021970799493, 0.932021970799493, 0.932021970799493]\n",
      "Mean 0.932\n"
     ]
    }
   ],
   "source": [
    "stacked1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did to combine the models?  Cross-validate the model. How well did it do?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation did not increase the acccuray. It decreased the accuracy by approx by 1.5%. \n",
    "But this gives us a more clear picture of the actual accuracy of the model which around 94%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
